import os
import json
import logging
import hashlib
import time
import requests
from typing import Dict, List, Tuple, Any, Optional

# Import OpenAI API key
from config.credentials import OPENAI_API_KEY
from config.settings import VIDEO_SETTINGS

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SceneVideoDetector:
    """
    Class to detect which scenes would benefit from video clips using OpenAI API,
    with optimization for cost and performance.
    """
    
    def __init__(self, cache_dir=None):
        """Initialize with OpenAI API key and optional cache directory."""
        self.openai_api_key = OPENAI_API_KEY
        if not self.openai_api_key:
            logger.error("OpenAI API key is missing. Scene video detection will fail.")
            raise ValueError("OpenAI API key is required for SceneVideoDetector")
            
        # Set up cache
        self.cache_dir = cache_dir or os.path.join(os.path.dirname(__file__), "../temp/scene_analysis_cache")
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # API settings
        self.openai_base_url = "https://api.openai.com/v1"
        self.openai_headers = {
            "Authorization": f"Bearer {self.openai_api_key}",
            "Content-Type": "application/json"
        }
        
        # Load keyword lists for preliminary filtering (used as optimization)
        self.action_keywords = [
            "running", "swimming", "flying", "moving", "walking", "driving",
            "demonstration", "protest", "celebration", "crowd", "traffic", "storm",
            "rain", "snow", "waves", "fire", "explosion", "collapse", "building",
            "construction", "process", "flow", "movement", "change", "transform"
        ]
        
        self.static_keywords = [
            "portrait", "still", "concept", "graph", "chart", "diagram", "abstract", 
            "landscape", "painting", "sculpture", "building", "architecture", "skyline"
        ]
        
    def analyze_script(self, script: Dict) -> Dict:
        """
        Analyze the entire script and determine which scenes should use video.
        
        Args:
            script (dict): The script generated by script_generator
            
        Returns:
            dict: The script with added 'prefer_video' flags for each scene
        """
        # Get video frequency from settings
        target_video_frequency = VIDEO_SETTINGS.get("video_clip_frequency", 0.5)
        min_scenes_between_videos = VIDEO_SETTINGS.get("min_scenes_between_videos", 1)
        
        scenes = script.get("scenes", [])
        if not scenes:
            logger.warning("No scenes found in script")
            return script
            
        logger.info(f"Analyzing {len(scenes)} scenes for video suitability")
        
        # First pass: Analyze each scene individually
        for scene in scenes:
            scene_number = scene.get("number", 0)
            content = scene.get("content", "")
            
            # Skip empty content
            if not content.strip():
                scene["video_score"] = 0.0
                scene["prefer_video"] = False
                scene["analysis_method"] = "skip_empty"
                continue
                
            # Try to get from cache first
            cached_result = self._check_cache(content)
            if cached_result:
                scene["video_score"] = cached_result["score"]
                scene["video_reason"] = cached_result["reason"]
                scene["analysis_method"] = "cache"
                logger.info(f"Scene {scene_number}: Using cached analysis (score: {cached_result['score']:.2f})")
                continue
                
            # Preliminary keyword-based assessment (optimization)
            preliminary_score = self._get_preliminary_score(content)
            
            # If clearly static or clearly dynamic based on keywords, skip API call
            if preliminary_score < 0.2:
                scene["video_score"] = preliminary_score
                scene["video_reason"] = "Static content based on keyword analysis"
                scene["prefer_video"] = False
                scene["analysis_method"] = "keywords_static"
                self._add_to_cache(content, preliminary_score, "Static content based on keyword analysis")
                logger.info(f"Scene {scene_number}: Static content (score: {preliminary_score:.2f})")
                continue
                
            if preliminary_score > 0.8:
                scene["video_score"] = preliminary_score
                scene["video_reason"] = "Dynamic content based on keyword analysis"
                scene["prefer_video"] = True
                scene["analysis_method"] = "keywords_dynamic"
                self._add_to_cache(content, preliminary_score, "Dynamic content based on keyword analysis")
                logger.info(f"Scene {scene_number}: Dynamic content (score: {preliminary_score:.2f})")
                continue
                
            # For scenes that need deeper analysis, use OpenAI API
            try:
                score, reason = self._analyze_with_openai(content)
                scene["video_score"] = score
                scene["video_reason"] = reason
                scene["analysis_method"] = "openai_api"
                self._add_to_cache(content, score, reason)
                logger.info(f"Scene {scene_number}: OpenAI analysis (score: {score:.2f})")
            except Exception as e:
                # Fallback to preliminary score if API fails
                logger.error(f"Error analyzing scene {scene_number} with OpenAI: {str(e)}")
                scene["video_score"] = preliminary_score
                scene["video_reason"] = "Preliminary score (API failed)"
                scene["analysis_method"] = "api_fallback"
                logger.info(f"Scene {scene_number}: Fallback to preliminary score: {preliminary_score:.2f}")
        
        # Second pass: Apply global distribution strategy
        self._apply_video_distribution_strategy(scenes, target_video_frequency, min_scenes_between_videos)
        
        # Log summary
        video_scenes = sum(1 for scene in scenes if scene.get("prefer_video", False))
        logger.info(f"Analysis complete. {video_scenes}/{len(scenes)} scenes marked for video content.")
        
        return script
    
    def _get_preliminary_score(self, content: str) -> float:
        """
        Get a preliminary score based on keyword matching.
        
        Args:
            content (str): The scene content
            
        Returns:
            float: A score between 0.0 and 1.0
        """
        content_lower = content.lower()
        
        # Count action and static keywords
        action_count = sum(1 for word in self.action_keywords if word in content_lower)
        static_count = sum(1 for word in self.static_keywords if word in content_lower)
        
        # Words that suggest more complex events
        event_phrases = ["taking place", "happened", "occurred", "unfolded", "breaking news", 
                        "captured on", "witnessed", "dramatic", "sudden", "rapidly", "quickly"]
        event_count = sum(1 for phrase in event_phrases if phrase in content_lower)
        
        # Base score calculation
        base_score = 0.5  # Neutral starting point
        
        # Adjust based on keyword counts
        action_factor = min(0.4, action_count * 0.1)  # Up to 0.4 from action words
        static_factor = min(0.4, static_count * 0.1)  # Up to 0.4 from static words
        event_factor = min(0.2, event_count * 0.05)   # Up to 0.2 from event phrases
        
        # Calculate final score
        score = base_score + action_factor - static_factor + event_factor
        
        # Ensure within bounds
        return max(0.0, min(1.0, score))
    
    def _analyze_with_openai(self, content: str) -> Tuple[float, str]:
        """
        Analyze a scene content with OpenAI API to determine if it should use video.
        
        Args:
            content (str): The scene content
            
        Returns:
            tuple: (score, reason) where score is between 0.0 and 1.0
        """
        prompt = f"""
        Your task is to analyze this scene description and determine if it would benefit from being visualized with a video clip (as opposed to a static image).

        Scene: "{content}"
        
        Rate on a scale of 0.0 to 1.0, where:
        - 0.0: Definitely use a static image (e.g., abstract concepts, portraits, still objects)
        - 0.5: Could work equally well with either image or video
        - 1.0: Definitely use video (e.g., action, movement, processes, events)
        
        Respond with a JSON object like:
        {{
          "score": 0.0-1.0,
          "reason": "Brief explanation of why this score was given"
        }}
        """
        
        try:
            url = f"{self.openai_base_url}/chat/completions"
            payload = {
                "model": "gpt-3.5-turbo",  # Using smaller model for cost efficiency
                "messages": [
                    {"role": "system", "content": "You are an AI specialized in video content analysis."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,  # Low temperature for consistency
                "max_tokens": 150    # Short response
            }
            
            response = requests.post(url, headers=self.openai_headers, json=payload, timeout=10)
            
            if response.status_code != 200:
                logger.error(f"OpenAI API error: {response.status_code}, {response.text}")
                raise Exception(f"OpenAI API error: {response.status_code}")
            
            data = response.json()
            
            # Extract JSON from response
            assistant_message = data["choices"][0]["message"]["content"].strip()
            
            try:
                # Try to parse JSON directly
                result = json.loads(assistant_message)
                
                # Validate the result
                if "score" not in result or "reason" not in result:
                    raise ValueError("Missing fields in response")
                
                score = float(result["score"])
                reason = result["reason"]
                
                # Ensure score is within bounds
                score = max(0.0, min(1.0, score))
                
                return score, reason
                
            except json.JSONDecodeError:
                # If not valid JSON, try to extract values using fallback method
                logger.warning(f"Failed to parse JSON response: {assistant_message}")
                
                # Simple fallback extraction
                if "score" in assistant_message and "reason" in assistant_message:
                    # Extract score using find
                    score_pos = assistant_message.find("score") + 5
                    score_end = assistant_message.find(",", score_pos)
                    score_str = assistant_message[score_pos:score_end].strip(" :\t\n\"'}")
                    score = float(score_str)
                    
                    # Extract reason
                    reason_pos = assistant_message.find("reason") + 6
                    reason_end = assistant_message.find("}", reason_pos)
                    reason = assistant_message[reason_pos:reason_end].strip(" :\t\n\"'")
                    
                    # Ensure score is within bounds
                    score = max(0.0, min(1.0, score))
                    
                    return score, reason
                    
                # If all else fails, return a neutral score
                return 0.5, "Failed to parse API response"
                
        except Exception as e:
            logger.error(f"Error calling OpenAI API: {str(e)}")
            raise
    
    def _check_cache(self, content: str) -> Optional[Dict]:
        """
        Check if a scene content has been analyzed before.
        
        Args:
            content (str): The scene content
            
        Returns:
            dict or None: Cached result or None if not found
        """
        # Generate hash for the content
        content_hash = hashlib.md5(content.encode()).hexdigest()
        cache_file = os.path.join(self.cache_dir, f"{content_hash}.json")
        
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"Error reading cache file {cache_file}: {str(e)}")
                return None
        
        return None
    
    def _add_to_cache(self, content: str, score: float, reason: str) -> None:
        """
        Add a scene analysis result to cache.
        
        Args:
            content (str): The scene content
            score (float): The video suitability score
            reason (str): The reason for the score
        """
        # Generate hash for the content
        content_hash = hashlib.md5(content.encode()).hexdigest()
        cache_file = os.path.join(self.cache_dir, f"{content_hash}.json")
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "score": score,
                    "reason": reason,
                    "timestamp": time.time()
                }, f)
        except Exception as e:
            logger.warning(f"Error writing to cache file {cache_file}: {str(e)}")
    
    def _apply_video_distribution_strategy(self, scenes: List[Dict], target_frequency: float, min_gap: int) -> None:
        """
        Apply a global strategy to distribute videos across scenes.
        
        Args:
            scenes (list): The list of scenes with video_score
            target_frequency (float): The target frequency of videos (0.0-1.0)
            min_gap (int): Minimum number of scenes between videos
        """
        # Sort scenes by video score while preserving original order
        scored_scenes = [(i, scene) for i, scene in enumerate(scenes)]
        scored_scenes.sort(key=lambda x: x[1].get("video_score", 0.0), reverse=True)
        
        # Calculate target number of videos
        target_videos = max(1, int(len(scenes) * target_frequency))
        
        # First mark top N scenes, respecting min_gap
        marked_indices = []
        for _, scene in scored_scenes:
            index = scene.get("number", 0) - 1  # Convert 1-based to 0-based
            
            # Skip if too close to already marked scenes
            if any(abs(index - marked_idx) <= min_gap for marked_idx in marked_indices):
                continue
                
            marked_indices.append(index)
            scene["prefer_video"] = True
            
            # Stop when we've marked enough scenes
            if len(marked_indices) >= target_videos:
                break
        
        # Mark remaining scenes as not preferring video
        for scene in scenes:
            if "prefer_video" not in scene:
                scene["prefer_video"] = False

# Integration with script_generator.py

def enhance_script_with_video_annotations(script):
    """
    Analyze script and determine which scenes should use video clips.
    
    Args:
        script (dict): The script generated by script_generator
        
    Returns:
        dict: The script with added 'prefer_video' flags
    """
    try:
        # Check if video clip feature is enabled
        if not VIDEO_SETTINGS.get("enable_video_clips", False):
            logger.info("Video clips feature is disabled. Skipping scene analysis.")
            # Mark all scenes as not preferring video
            for scene in script.get("scenes", []):
                scene["prefer_video"] = False
            return script
            
        # Initialize detector
        detector = SceneVideoDetector()
        
        # Analyze script
        enhanced_script = detector.analyze_script(script)
        
        return enhanced_script
        
    except Exception as e:
        logger.error(f"Error enhancing script with video annotations: {str(e)}")
        # Fallback: Mark all scenes as not preferring video
        for scene in script.get("scenes", []):
            scene["prefer_video"] = False
        return script


# Direct testing
if __name__ == "__main__":
    # Test with some example scenes
    test_scenes = [
        "The stock market showed significant gains today, with the S&P 500 rising 2.3% to close at an all-time high.",
        "Protesters marched through downtown, waving signs and chanting slogans as police monitored the situation.",
        "The new study reveals a correlation between coffee consumption and increased productivity in office workers.",
        "Heavy rainfall caused flash flooding across the region, with cars being swept away by rushing water.",
        "The painting, valued at over $2 million, will be displayed in the museum's main gallery starting next week."
    ]
    
    detector = SceneVideoDetector()
    
    print("Testing scene analysis:")
    for i, scene in enumerate(test_scenes):
        try:
            score, reason = detector._analyze_with_openai(scene)
            preliminary = detector._get_preliminary_score(scene)
            print(f"\nScene {i+1}:")
            print(f"Content: {scene}")
            print(f"Preliminary score: {preliminary:.2f}")
            print(f"OpenAI score: {score:.2f}")
            print(f"Reason: {reason}")
            print(f"Would use video: {'Yes' if score > 0.6 else 'No'}")
        except Exception as e:
            print(f"Error analyzing scene {i+1}: {str(e)}")